{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('trainset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation=pd.read_csv('testset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "todrop=df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    #print(df[col].unique())\n",
    "    if df[col].isna().sum()>500:\n",
    "        df=df.drop(col,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7140, 1428)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.cls.values\n",
    "#x=df.drop('cls',axis=1).drop('ABC',axis=1).drop('ABCGG',axis=1).drop('n5FAHRing',axis=1).values\n",
    "x=df.drop('cls',axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class dtset(Dataset):\n",
    "    \n",
    "    # Init\n",
    "    def __init__(self,data,labels):\n",
    "        self.data=torch.FloatTensor(data)\n",
    "        self.labels=torch.FloatTensor(labels)\n",
    "    \n",
    "    # len\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    # obtain item\n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx],self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder to reduce dimensionality\n",
    "class Autoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, encoding_dim):\n",
    "        \n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 800),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(800,400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16,encoding_dim)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400,800),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(800,input_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        \n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request info on why ABC, ABCGG,nAcid,nBase are 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size,num_classes=2,drop_per=0.03):\n",
    "        \n",
    "        super(cnn,self).__init__()\n",
    "        \n",
    "        # 1st convolution\n",
    "        self.conv1d1 = nn.Conv1d(in_channels=input_size,out_channels=200,kernel_size=3)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool1d(kernel_size=3)\n",
    "        self.dropout1 = nn.Dropout(p=drop_per)\n",
    "        \n",
    "        # 2nd convolution \n",
    "        self.conv1d2 = nn.Conv1d(in_channels=200,out_channels=150,kernel_size=3)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool1d(kernel_size=3)\n",
    "        self.dropout2 = nn.Dropout(p=drop_per)\n",
    "        \n",
    "        # 3rd convolution\n",
    "        self.conv1d3 = nn.Conv1d(in_channels=150,out_channels=100,kernel_size=3)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool1d(kernel_size=3)\n",
    "        self.dropout3 = nn.Dropout(p=drop_per)\n",
    "        \n",
    "        # 4th convolution\n",
    "        self.conv1d4 = nn.Conv1d(in_channels=100,out_channels=50,kernel_size=3)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.maxpool4 = nn.MaxPool1d(kernel_size=3)\n",
    "        self.dropout4 = nn.Dropout(p=drop_per)\n",
    "        \n",
    "        # 5th convolution\n",
    "        self.conv1d5 = nn.Conv1d(in_channels=50,out_channels=1,kernel_size=3)\n",
    "        self.sigmoid1 = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # 1st convolution\n",
    "        x = self.conv1d1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        # 2nd convolution\n",
    "        x = self.conv1d2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        # 3rd convolution\n",
    "        x = self.conv1d3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        # 4th convolution\n",
    "        x = self.conv1d4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.maxpool4(x)\n",
    "        x = self.dropout4(x)\n",
    "\n",
    "        # 5th convolution\n",
    "        x = self.conv1d5(x)\n",
    "        x = self.sigmoid1(x)\n",
    "\n",
    "        # Flatten the output\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1427"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "\n",
    "# create dataset objects\n",
    "train=dtset(x_train,y_train)\n",
    "test=dtset(x_test,y_test)\n",
    "\n",
    "# create loaders\n",
    "train_loader=DataLoader(train,batch_size=batch_size,shuffle=True)\n",
    "test_loader=DataLoader(test,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5712, 1427), (5712,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame([i for i in train_loader])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1428, 1427), (1428,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "encoding_dims=240\n",
    "# Init autoencoder\n",
    "ae=Autoencoder(input_size=size,encoding_dim=encoding_dims)\n",
    "\n",
    "# Init autoencoder loss func MSE\n",
    "ae_loss_func=nn.MSELoss()\n",
    "\n",
    "# Init autencoder optimzer adam\n",
    "ae_optimizer=optim.Adam(ae.parameters(),lr=0.001 , eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init model\n",
    "model=cnn(input_size=encoding_dims, num_classes=2, drop_per=0.03)\n",
    "\n",
    "# Init loss func crossentropy\n",
    "loss_func=nn.CrossEntropyLoss()\n",
    "\n",
    "# Init optimizer adam\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001, eps = 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 68154.1719\n",
      "Epoch [2/50], Loss: 79275.2422\n",
      "Epoch [3/50], Loss: 121774.8984\n",
      "Epoch [4/50], Loss: 77668.2344\n",
      "Epoch [5/50], Loss: 66556.8516\n",
      "Epoch [6/50], Loss: 99196.5938\n",
      "Epoch [7/50], Loss: 88342.2578\n",
      "Epoch [8/50], Loss: 83829.0078\n",
      "Epoch [9/50], Loss: 138263.0938\n",
      "Epoch [10/50], Loss: 81189.1641\n",
      "Epoch [11/50], Loss: 61568.8789\n",
      "Epoch [12/50], Loss: 89720.0703\n",
      "Epoch [13/50], Loss: 75897.9922\n",
      "Epoch [14/50], Loss: 162435.7656\n",
      "Epoch [15/50], Loss: 93446.5234\n",
      "Epoch [16/50], Loss: 74760.0391\n",
      "Epoch [17/50], Loss: 65288.0547\n",
      "Epoch [18/50], Loss: 256023.5938\n",
      "Epoch [19/50], Loss: 69249.1250\n",
      "Epoch [20/50], Loss: 82539.6016\n",
      "Epoch [21/50], Loss: 70226.3906\n",
      "Epoch [22/50], Loss: 106926.1250\n",
      "Epoch [23/50], Loss: 64535.0859\n",
      "Epoch [24/50], Loss: 76353.8672\n",
      "Epoch [25/50], Loss: 59256.5039\n",
      "Epoch [26/50], Loss: 248295.0469\n",
      "Epoch [27/50], Loss: 96327.4922\n",
      "Epoch [28/50], Loss: 99802.3125\n",
      "Epoch [29/50], Loss: 77348.3984\n",
      "Epoch [30/50], Loss: 90387.8828\n",
      "Epoch [31/50], Loss: 109000.9141\n",
      "Epoch [32/50], Loss: 68648.2969\n",
      "Epoch [33/50], Loss: 80063.6016\n",
      "Epoch [34/50], Loss: 92463.1250\n",
      "Epoch [35/50], Loss: 79631.5938\n",
      "Epoch [36/50], Loss: 92283.6719\n",
      "Epoch [37/50], Loss: 54983.2500\n",
      "Epoch [38/50], Loss: 112251.4688\n",
      "Epoch [39/50], Loss: 66075.8750\n",
      "Epoch [40/50], Loss: 115184.5938\n",
      "Epoch [41/50], Loss: 59036.0312\n",
      "Epoch [42/50], Loss: 89868.7969\n",
      "Epoch [43/50], Loss: 158607.4688\n",
      "Epoch [44/50], Loss: 61620.6211\n",
      "Epoch [45/50], Loss: 71139.5234\n",
      "Epoch [46/50], Loss: 84916.2578\n",
      "Epoch [47/50], Loss: 90335.8438\n",
      "Epoch [48/50], Loss: 60051.4102\n",
      "Epoch [49/50], Loss: 115184.9297\n",
      "Epoch [50/50], Loss: 151728.5625\n"
     ]
    }
   ],
   "source": [
    "ae_epochs=50\n",
    "\n",
    "# Run for epochs\n",
    "for epoch in range(ae_epochs):\n",
    "    # Run for items in loader\n",
    "    for data in train_loader:\n",
    "        inputs,_=data # ignore labels\n",
    "        ae_optimizer.zero_grad()\n",
    "        encoded,decoded=ae(inputs)\n",
    "        ae_loss=ae_loss_func(decoded,inputs)\n",
    "        ae_loss.backward()\n",
    "        ae_optimizer.step()\n",
    "    print(f'Epoch [{epoch + 1}/{ae_epochs}], Loss: {ae_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [200, 240, 3], expected input[1, 64, 1427] to have 240 channels, but got 64 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/ajdj/clones/cancer-detection/cnn.ipynb Cell 24\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X32sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m inputs,labels \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X32sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X32sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     outputs\u001b[39m=\u001b[39mmodel(inputs)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X32sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     loss\u001b[39m=\u001b[39mloss_func(outputs,labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X32sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/mnt/stor/miniconda/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/ajdj/clones/cancer-detection/cnn.ipynb Cell 24\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X32sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X32sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X32sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39m# 1st convolution\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X32sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1d1(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X32sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu1(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X32sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxpool1(x)\n",
      "File \u001b[0;32m/mnt/stor/miniconda/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/stor/miniconda/envs/torch/lib/python3.11/site-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/mnt/stor/miniconda/envs/torch/lib/python3.11/site-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [200, 240, 3], expected input[1, 64, 1427] to have 240 channels, but got 64 channels instead"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs=10\n",
    "\n",
    "# Run for epochs\n",
    "for epoch in range(epochs):\n",
    "    # Run for items in loader\n",
    "    for inputs,labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs=model(inputs)\n",
    "        loss=loss_func(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "       \n",
    "# Save\n",
    "torch.save(ae.state_dict(),'models/autoencoder.pth')\n",
    "torch.save(model.state_dict(),'models/model.pth')\n",
    "\n",
    "# Load\n",
    "ae.load_state_dict(torch.load('models/autoencoder.pth'))\n",
    "model.load_state_dict(torch.load('models/model.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
