{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('trainset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation=pd.read_csv('testset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "todrop=df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    #print(df[col].unique())\n",
    "    if df[col].isna().sum()>500:\n",
    "        df=df.drop(col,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7140, 1428)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.cls.values\n",
    "#x=df.drop('cls',axis=1).drop('ABC',axis=1).drop('ABCGG',axis=1).drop('n5FAHRing',axis=1).values\n",
    "x=df.drop('cls',axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class dtset(Dataset):\n",
    "    \n",
    "    # Init\n",
    "    def __init__(self,data,labels):\n",
    "        self.data=torch.FloatTensor(data)\n",
    "        self.labels=torch.FloatTensor(labels)\n",
    "    \n",
    "    # len\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    # obtain item\n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx],self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder to reduce dimensionality\n",
    "class Autoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, encoding_dim):\n",
    "        \n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size,int(input_size/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(input_size/2),int(input_size/4)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(input_size/4),int(input_size/8)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(input_size/8),encoding_dim)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim,int(input_size/8)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(input_size/8),int(input_size/4)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(input_size/4),int(input_size/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(input_size/2),input_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        \n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request info on why ABC, ABCGG,nAcid,nBase are 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size,num_classes=2,drop_per=0.03):\n",
    "        \n",
    "        super(cnn,self).__init__()\n",
    "        \n",
    "        # 1st convolution\n",
    "        self.conv1d1 = nn.Conv1d(in_channels=input_size,out_channels=200,kernel_size=3)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool1d(kernel_size=3)\n",
    "        self.dropout1 = nn.Dropout(p=drop_per)\n",
    "        \n",
    "        # 2nd convolution \n",
    "        self.conv1d2 = nn.Conv1d(in_channels=200,out_channels=150,kernel_size=3)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool1d(kernel_size=3)\n",
    "        self.dropout2 = nn.Dropout(p=drop_per)\n",
    "        \n",
    "        # 3rd convolution\n",
    "        self.conv1d3 = nn.Conv1d(in_channels=150,out_channels=100,kernel_size=3)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool1d(kernel_size=3)\n",
    "        self.dropout3 = nn.Dropout(p=drop_per)\n",
    "        \n",
    "        # 4th convolution\n",
    "        self.conv1d4 = nn.Conv1d(in_channels=100,out_channels=50,kernel_size=3)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.maxpool4 = nn.MaxPool1d(kernel_size=3)\n",
    "        self.dropout4 = nn.Dropout(p=drop_per)\n",
    "        \n",
    "        # 5th convolution\n",
    "        self.conv1d5 = nn.Conv1d(in_channels=50,out_channels=1,kernel_size=3)\n",
    "        self.sigmoid1 = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # 1st convolution\n",
    "        x = self.conv1d1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        # 2nd convolution\n",
    "        x = self.conv1d2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        # 3rd convolution\n",
    "        x = self.conv1d3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        # 4th convolution\n",
    "        x = self.conv1d4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.maxpool4(x)\n",
    "        x = self.dropout4(x)\n",
    "\n",
    "        # 5th convolution\n",
    "        x = self.conv1d5(x)\n",
    "        x = self.sigmoid1(x)\n",
    "\n",
    "        # Flatten the output\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1427"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "\n",
    "# create dataset objects\n",
    "train=dtset(x_train,y_train)\n",
    "test=dtset(x_test,y_test)\n",
    "\n",
    "# create loaders\n",
    "train_loader=DataLoader(train,batch_size=batch_size,shuffle=True)\n",
    "test_loader=DataLoader(test,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5712, 1427), (5712,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame([i for i in train_loader])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1428, 1427), (1428,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ajdj/clones/cancer-detection/cnn.ipynb Cell 21\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m encoding_dims\u001b[39m=\u001b[39mbatch_size\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Init autoencoder\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m ae\u001b[39m=\u001b[39mAutoencoder(input_size\u001b[39m=\u001b[39;49msize,encoding_dim\u001b[39m=\u001b[39;49mencoding_dims)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Init autoencoder loss func MSE\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ae_loss_func\u001b[39m=\u001b[39mnn\u001b[39m.\u001b[39mMSELoss()\n",
      "\u001b[1;32m/home/ajdj/clones/cancer-detection/cnn.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39msuper\u001b[39m(Autoencoder, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     nn\u001b[39m.\u001b[39mLinear(input_size,\u001b[39mint\u001b[39m(input_size\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m)),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     nn\u001b[39m.\u001b[39mReLU(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X26sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     nn\u001b[39m.\u001b[39mLinear(\u001b[39mint\u001b[39m(input_size\u001b[39m/\u001b[39m\u001b[39m8\u001b[39m),encoding_dim)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X26sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X26sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X26sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     nn\u001b[39m.\u001b[39mLinear(encoding_dim, \u001b[39m8\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X26sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     nn\u001b[39m.\u001b[39mReLU(),\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X26sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     nn\u001b[39m.\u001b[39;49mLinear(input_size\u001b[39m/\u001b[39;49m\u001b[39m8\u001b[39;49m,input_size\u001b[39m/\u001b[39;49m\u001b[39m4\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X26sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     nn\u001b[39m.\u001b[39mReLU(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X26sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     nn\u001b[39m.\u001b[39mLinear(input_size\u001b[39m/\u001b[39m\u001b[39m4\u001b[39m,input_size\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X26sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     nn\u001b[39m.\u001b[39mReLU(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X26sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     nn\u001b[39m.\u001b[39mLinear(input_size\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m,input_size)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ajdj/clones/cancer-detection/cnn.ipynb#X26sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m )\n",
      "File \u001b[0;32m/mnt/stor/miniconda/envs/torch/lib/python3.11/site-packages/torch/nn/modules/linear.py:96\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_features \u001b[39m=\u001b[39m in_features\n\u001b[1;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_features \u001b[39m=\u001b[39m out_features\n\u001b[0;32m---> 96\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39;49mempty((out_features, in_features), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfactory_kwargs))\n\u001b[1;32m     97\u001b[0m \u001b[39mif\u001b[39;00m bias:\n\u001b[1;32m     98\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty(out_features, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs))\n",
      "\u001b[0;31mTypeError\u001b[0m: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "encoding_dims=batch_size\n",
    "# Init autoencoder\n",
    "ae=Autoencoder(input_size=size,encoding_dim=encoding_dims)\n",
    "\n",
    "# Init autoencoder loss func MSE\n",
    "ae_loss_func=nn.MSELoss()\n",
    "\n",
    "# Init autencoder optimzer adam\n",
    "ae_optimizer=optim.Adam(ae.parameters(),lr=0.001 , eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init model\n",
    "model=cnn(input_size=encoding_dims, num_classes=2, drop_per=0.03)\n",
    "\n",
    "# Init loss func binary-crossentropy\n",
    "loss_func=nn.BCELoss()\n",
    "\n",
    "# Init optimizer adam\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001, eps = 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_epochs=100\n",
    "\n",
    "# Run for epochs\n",
    "for epoch in range(ae_epochs):\n",
    "    # Run for items in loader\n",
    "    for data in train_loader:\n",
    "        inputs,_=data # ignore labels\n",
    "        ae_optimizer.zero_grad()\n",
    "        encoded,decoded=ae(inputs)\n",
    "        ae_loss=ae_loss_func(decoded,inputs)\n",
    "        ae_loss.backward()\n",
    "        ae_optimizer.step()\n",
    "    print(f'Epoch [{epoch + 1}/{ae_epochs}], Loss: {ae_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs=10\n",
    "\n",
    "# Run for epochs\n",
    "for epoch in range(epochs):\n",
    "    # Run for items in loader\n",
    "    for inputs,labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs=model(inputs)\n",
    "        loss=loss_func(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "       \n",
    "# Save\n",
    "torch.save(ae.state_dict(),'models/autoencoder.pth')\n",
    "torch.save(model.state_dict(),'models/model.pth')\n",
    "\n",
    "# Load\n",
    "ae.load_state_dict(torch.load('models/autoencoder.pth'))\n",
    "model.load_state_dict(torch.load('models/model.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
